{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7441bc35",
   "metadata": {},
   "source": [
    "עמית טיקוצינסקי - 206963985\n",
    "קובי קראדי - 208748566"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf6a4e",
   "metadata": {},
   "source": [
    "https://github.com/amittiko/cars_prediction.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a58ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9d619a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def prepare_data(dataset):\n",
    "    # Ensure we are working with a copy to avoid warnings\n",
    "    dataset = dataset.copy()\n",
    "    \n",
    "    # Drop rows with NaN in specific columns\n",
    "    dataset = dataset.dropna(subset=[\"Gear\"])\n",
    "    dataset = dataset.dropna(subset=[\"capacity_Engine\"])\n",
    "    dataset = dataset.dropna(subset=[\"Engine_type\"])\n",
    "\n",
    "    # Fill NaN values in 'Color' and replace specific values\n",
    "    dataset['Color'] = dataset['Color'].fillna('חסר צבע')\n",
    "    dataset['Color'] = dataset['Color'].replace(\"None\", 'חסר צבע')\n",
    "    \n",
    "    # המיפוי לצבעים מאוחדים\n",
    "    color_mapping = {\n",
    "        'כחול כהה מטאלי': 'כחול',\n",
    "        'כחול בהיר': 'כחול',\n",
    "        'אפור מטאלי': 'אפור',\n",
    "        'חסר צבע': 'חסר צבע',\n",
    "        'שחור': 'שחור',\n",
    "        'חום': 'חום',\n",
    "        'כסוף': 'כסף',\n",
    "        'לבן': 'לבן',\n",
    "        'לבן מטאלי': 'לבן',\n",
    "        'לבן פנינה': 'לבן',\n",
    "        'אפור עכבר': 'אפור',\n",
    "        'אפור': 'אפור',\n",
    "        'כחול': 'כחול',\n",
    "        'סגול': 'סגול',\n",
    "        'אדום': 'אדום',\n",
    "        'כסף מטלי': 'כסף',\n",
    "        'כתום': 'כתום',\n",
    "        'לבן שנהב': 'לבן',\n",
    "        'סגול חציל': 'סגול',\n",
    "        'כסוף מטאלי': 'כסף',\n",
    "        'כחול בהיר מטאלי': 'כחול',\n",
    "        'טורקיז': 'טורקיז',\n",
    "        \"בז'\": 'בז',\n",
    "        'בורדו': 'בורדו',\n",
    "        'ירוק': 'ירוק',\n",
    "        'שמפניה': 'לבן',\n",
    "        'ירוק מטאלי': 'ירוק',\n",
    "        'תכלת': 'תכלת',\n",
    "        'חום מטאלי': 'חום',\n",
    "        'אדום מטאלי': 'אדום',\n",
    "        'כחול מטאלי': 'כחול',\n",
    "        \"בז' מטאלי\": 'בז',\n",
    "        'ורוד': 'ורוד',\n",
    "        'ברונזה': 'ברונזה',\n",
    "        'ירוק בהיר': 'ירוק',\n",
    "        'זהב מטאלי': 'זהב',\n",
    "        'תכלת מטאלי': 'תכלת',\n",
    "        'זהב': 'זהב'\n",
    "    }\n",
    "\n",
    "    # פונקציה להחלפת הערכים על פי המיפוי\n",
    "    def map_colors(dataset):\n",
    "        dataset['Color'] = dataset['Color'].map(color_mapping).fillna(dataset['Color'])\n",
    "        return dataset\n",
    "\n",
    "    # להחיל את הפונקציה על הדאטה סט שלך\n",
    "    dataset = map_colors(dataset)\n",
    "\n",
    "    # Correcting specific values\n",
    "    replacements = {\n",
    "        'manufactor': {\"Lexsus\": 'לקסוס'},\n",
    "        'Gear': {\"אוטומט\": 'אוטומטית'},\n",
    "        'Engine_type': {\"היבריד\": 'היברידי', \"טורבו דיזל\": 'דיזל'},\n",
    "        'Prev_ownership': {\"אחר\": 'לא מוגדר', \"None\": 'לא מוגדר'},\n",
    "        'Curr_ownership': {\"אחר\": 'לא מוגדר', \"None\": 'לא מוגדר'},\n",
    "        'City': {\n",
    "            \"ashdod\": 'אשדוד', \"Tel aviv\": 'תל אביב יפו', \"Tzur Natan\": 'צור נתן',\n",
    "            \"haifa\": 'חיפה', \"Rehovot\": 'רחובות', \"jeruslem\": 'ירושלים', \n",
    "            \"Rishon LeTsiyon\": 'ראשון לציון', 'פ\"ת': 'פתח תקווה', \n",
    "            'פתח': 'פתח תקווה', \"תל\": 'תל אביב יפו', \"תל אביב\": 'תל אביב יפו', \n",
    "            \"מזכרת\": 'מזכרת בתיה', \"ק.אתא\": 'קריית אתא', \"באקה\": 'באקה אל גרבייה', \n",
    "            \"חיפ\": 'חיפה'\n",
    "        }\n",
    "    }\n",
    "    for column, replace_dict in replacements.items():\n",
    "        dataset[column] = dataset[column].replace(replace_dict)\n",
    "    \n",
    "    dataset = dataset.query('Gear != \"לא מוגדר\"')\n",
    "    dataset['capacity_Engine'] = dataset['capacity_Engine'].str.replace(',', '', regex=True)\n",
    "\n",
    "    # Fill NaN values in 'Prev_ownership' and 'Curr_ownership'\n",
    "    dataset['Prev_ownership'] = dataset['Prev_ownership'].fillna('לא מוגדר')\n",
    "    dataset['Curr_ownership'] = dataset['Curr_ownership'].fillna('לא מוגדר')\n",
    "\n",
    "    # Filter out specific cities\n",
    "    dataset = dataset.query('City not in [\"ראש\", \"הוד\", \"פתח תקווה,יהוד\", \"חד\", \"אבן\", \"כפר\", \"בת\", \"רא\", \"רמת\",\"קרית\",\"אומן\"]')\n",
    "\n",
    "    # Fill NaN values in 'Pic_num' with 0\n",
    "    dataset['Pic_num'] = dataset['Pic_num'].fillna(0)\n",
    "\n",
    "    # Remove rows where 'Km' is \"None\"\n",
    "    dataset = dataset.query('Km != \"None\"')\n",
    "    dataset['Km'] = dataset['Km'].str.replace(',', '', regex=True)\n",
    "\n",
    "    # Convert 'Cre_date' and 'Repub_date' to datetime\n",
    "    def to_datetime(x):\n",
    "        try:\n",
    "            return pd.to_datetime(x)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    dataset['Cre_date'] = dataset['Cre_date'].apply(to_datetime)\n",
    "    dataset = dataset[dataset['Cre_date'].notnull()]\n",
    "\n",
    "    dataset['Repub_date'] = dataset['Repub_date'].apply(to_datetime)\n",
    "    dataset = dataset[dataset['Repub_date'].notnull()]\n",
    "\n",
    "    # Correct specific model values\n",
    "    model_replacements = {\n",
    "        \"V- CLASS\": 'V-Class', \"E- CLASS\": 'E-Class', \"S- CLASS\": 'S-Class',\n",
    "        \"Taxi\": 'C-Class', \"CIVIC\": 'סיוויק', \"JAZZ\": 'ג\\'אז', \"ACCORD\": 'אקורד',\n",
    "        \"CLASS\": 'C-Class', \"X\": 'מוקה X'\n",
    "    }\n",
    "    dataset['model'] = dataset['model'].replace(model_replacements)\n",
    "\n",
    "    # Function to clean and extract the model name\n",
    "    def get_model(car_name):\n",
    "        car_name = re.sub(r'\\(.*?\\)', '', car_name)\n",
    "        car_name = re.sub(r'\\b(החדש|חדש|חדשה|החדשה)\\b', '', car_name)\n",
    "        parts = car_name.split()\n",
    "        if len(parts) > 1:\n",
    "            if any(char.isdigit() for char in parts[1].replace(\" \", \"\")):\n",
    "                return ' '.join(parts[1:])\n",
    "            else:\n",
    "                model = ' '.join(parts[1:]).strip()\n",
    "                model = re.sub(r'\\d+', '', model).strip()\n",
    "                return model if model else parts[1]\n",
    "        else:\n",
    "            return car_name\n",
    "\n",
    "    dataset['model'] = dataset['model'].apply(get_model)\n",
    "\n",
    "    # Function to remove extra spaces and characters\n",
    "    def clean_car_name(car_name):\n",
    "        car_name = car_name.strip()\n",
    "        car_name = re.sub(r'\\s?/.*', '', car_name)\n",
    "        return car_name\n",
    "\n",
    "    dataset['model'] = dataset['model'].apply(clean_car_name)\n",
    "    \n",
    "    #הורדת שנים חריגים\n",
    "    dataset = dataset[dataset['Year'] > 1988]\n",
    "\n",
    "    # חישוב גיל הרכב\n",
    "    current_year = datetime.now().year\n",
    "    dataset['Car_Age'] = current_year - dataset['Year']\n",
    "\n",
    "    # הורדת עמודות עם הרבה נאנים או עם הרבה שגיאות\n",
    "    dataset.drop([\"Supply_score\", \"Test\", \"Area\"], axis=1, inplace=True)\n",
    "\n",
    "    # Convert 'Km' to numeric and fill missing values \n",
    "    dataset['Km'] = pd.to_numeric(dataset['Km'], errors='coerce').astype('Int64')\n",
    "    dataset['Km'] = dataset['Km'].where(dataset['Km'] >= 1000, dataset['Km'] * 1000)\n",
    "    dataset = dataset.drop(dataset[dataset['Km'] == 0].index)\n",
    "    \n",
    "    mean_km_by_year = dataset.groupby('Year')['Km'].median()\n",
    "    dataset['Km'] = dataset.apply(lambda row: mean_km_by_year[row['Year']] if pd.isnull(row['Km']) else row['Km'], axis=1)\n",
    "\n",
    "   \n",
    "    # Ensure correct data types\n",
    "    dataset['manufactor'] = dataset['manufactor'].astype(str)\n",
    "    dataset['Year'] = dataset['Year'].astype(int)\n",
    "    dataset['model'] = dataset['model'].astype(str)\n",
    "    dataset['Hand'] = dataset['Hand'].astype(int)\n",
    "    dataset['Gear'] = dataset['Gear'].astype('category')\n",
    "    dataset['capacity_Engine'] = dataset['capacity_Engine'].astype(int)\n",
    "    dataset['Engine_type'] = dataset['Engine_type'].astype('category')\n",
    "    dataset['Prev_ownership'] = dataset['Prev_ownership'].astype('category')\n",
    "    dataset['Curr_ownership'] = dataset['Curr_ownership'].astype('category')\n",
    "    dataset['City'] = dataset['City'].astype(str)\n",
    "    dataset['Price'] = dataset['Price'].astype(float)\n",
    "    dataset['Pic_num'] = dataset['Pic_num'].astype(int)\n",
    "    dataset['Description'] = dataset['Description'].astype(str)\n",
    "    dataset['Color'] = dataset['Color'].astype(str)\n",
    "    \n",
    "    #regions\n",
    "    north = [\n",
    "    'חיפה', 'כרמיאל', 'ריינה', 'נהריה', \"בית ג'ן\", 'טירת כרמל', 'עכו', 'קרית אתא',\n",
    "    'זרזיר', 'בית שאן', 'נוף הגליל', 'באקה אל גרבייה', 'באקה א שרקיה', 'יוקנעם',\n",
    "    'מגדל העמק', 'עפולה', 'ראש פינה', 'באקה אל-גרביה', 'צפת', 'טירת הכרמל',\n",
    "    'בוקעתא', 'אעבלין', 'טבריה', 'עין מאהל', 'מרר', 'נצרת עילית', 'זכרון יעקב',\n",
    "    'קרית ביאליק', 'קריית אתא', 'נצרת', 'עתלית', 'קרית שמונה', 'משמר השרון',\n",
    "    'אלמגור', 'כאבול', 'קרית טבעון', 'כפר מנדא', 'פוריידיס', 'עספיא', 'שריד',\n",
    "    'אילת השחר', \"סח'נין\", 'כפר תבור', 'ריחאניה', 'יובלים', 'פוריה', 'אום אל פחם',\n",
    "    'עראבה', 'גילון', 'תמרת', 'שפרעם', 'ערערה', 'נשר', 'דאלית אל כרמל', 'קריית ביאליק',\n",
    "    'החותרים', 'אבו סנאן', 'נחף', \"מג'ד אל-כרום\", 'מגאר', 'מעלות תרשיחא', 'אילון',\n",
    "    'חד נס', 'אבני איתן', 'ארבל', 'רכסים', 'כפר כנא', \"בית ג'אן\", 'קצרין', 'נווה אור',\n",
    "    'גבעת אלה', 'פקיעין', 'כמון', 'מעלות', 'נהרייה', 'דבוריה', 'כסרא', 'בית קשת',\n",
    "    'טמרה', 'קרית ים', 'כפר קרע', 'מזרעה', 'מצפה נטופה ד.נ. גליל תחתון', 'סאגור',\n",
    "    'יקנעם עילית', 'נאעורה', 'סלמה', 'מגדל', 'יוקנעם עילית', 'חדרה',\"קרית מוצקין\",\"גבעת אבני\",\"קריית ים\",\"רמת מגשימים\",\"כפר מצר\"\n",
    "    ]\n",
    "\n",
    "    judea_and_samaria = [\n",
    "        'עלי זהב', 'חשמונאים', 'ביתר עילית', 'מתתיהו', 'אלעזר', 'כפר תפוח',\n",
    "        'מעלה אדומים', 'אריאל', 'גבע בנימין', 'בת עין', 'קרית ארבע',\"רבבה\"\n",
    "    ]\n",
    "\n",
    "    south = [\n",
    "        'באר שבע', 'עומר', 'שדרות', 'דימונה', 'קרית גת', 'שגב שלום', 'נחלה', 'נתיבות',\n",
    "        'מושב מולדת', 'אילת', 'אופקים', 'תל שבע', 'שתולים', 'כסיפה', 'ברוש', 'מעגלים',\n",
    "        'קציר', 'חורה', 'מיתר', 'להבים', 'עוצם', 'אשדוד', 'אשקלון', 'קרית מלאכי',\"בניה\",\"שריגים\"\n",
    "    ]\n",
    "\n",
    "    center = [\n",
    "        'רעננה', 'אבן יהודה', 'רחובות', 'ראשון לציון', 'פתח תקווה', 'ירכא', 'בית דגן',\n",
    "        'בת ים', 'חולון', 'גדרה', 'נס ציונה', 'גן יבנה', 'רמת גן', 'כפר סבא', 'בני ברק',\n",
    "        'תל יצחק', 'תל אביב יפו', 'ראש העין', 'כפר יונה', 'גבעת שמואל', 'נתניה', 'ברקת',\n",
    "        'שוהם', 'פרדס', 'גבעתיים', 'תל מונד', 'תנובות', 'אליכין', 'הוד השרון',\n",
    "        'הרצליה', 'זמר', 'מכמורת', 'בית עוזיאל', 'אור עקיבא', 'אודים', 'קיסריה',\n",
    "        'חרוצים', 'כפר יעבץ', 'בנימינה גבעת עדה', 'לוד', 'עזריאל',\n",
    "        'מודיעין מכבים רעות', 'מודיעין', 'כפר הרי\"ף', 'אלעד', 'קדרון', 'אור יהודה',\n",
    "        'רמלה', 'אורנית', 'רמת השרון', 'קרית אונו', 'שער אפרים', 'זכריה',\n",
    "        'פרדס חנה כרכור', 'יהוד מונוסון', 'אחיטוב', 'אזור', 'אחיעזר', 'גבעת כ\"ח',\n",
    "        'תל אבייב', 'יבנה', 'גבעתי', 'יהוד', 'עטרת', 'בית', 'חיננית', 'חופית', 'טייבה',\n",
    "        'גני תקווה', 'יד בנימין', 'מגשימים', 'גבעתיי', 'קריות', 'ראשון', 'באר יעקב',\n",
    "        'שערי תקווה', 'בארותיים', 'עמק חפר', 'פתח תיקווה', 'מזכרת בתיה', 'כפר חב\"ד',\n",
    "        'צפריה', 'חריש', 'רשפון', 'גן השומרון', 'מודיעין עילית', 'קרית עקרון',\n",
    "        'כוכב יאיר', 'כפר מנחם', 'טירה', 'מתן', 'ניר צבי', 'קלנסווה', 'רמת ישי',\n",
    "        'קדימה צורן', 'כפר עגר', 'סלעית', 'גבעת עדה', 'צור נתן', 'נגבה', 'נתנייה',\n",
    "        'כפר קאסם',\"צור יצחק\",\"טייבה משולש\",\"גבעת חיים מאוחד\"\n",
    "    ]\n",
    "\n",
    "    jerusalem_and_surroundings = [\n",
    "        'ירושלים', 'מבשרת ציון', 'בית שמש', 'צור הדסה', 'קרית יערים', 'אבו גוש',\n",
    "        'עזריה', 'אורה', 'בית זית', 'פסגת זאב', 'גבעת זאב'\n",
    "    ]\n",
    "\n",
    "    def map_city_to_region(city):\n",
    "        if city in north:\n",
    "            return 'צפון'\n",
    "        elif city in judea_and_samaria:\n",
    "            return 'יהודה ושומרון'\n",
    "        elif city in south:\n",
    "            return 'דרום'\n",
    "        elif city in center:\n",
    "            return 'מרכז'\n",
    "        elif city in jerusalem_and_surroundings:\n",
    "            return 'ירושלים והסביבה'\n",
    "        else:\n",
    "            return 'לא ידוע'\n",
    "\n",
    "    # בהנחה שה-DataFrame שלכם נקרא df ויש לו עמודה בשם 'City'\n",
    "    dataset['Region'] = dataset['City'].apply(map_city_to_region)\n",
    "\n",
    "\n",
    "    # Drop columns with too many NaNs or irrelevant columns\n",
    "    dataset.drop([\"Prev_ownership\", \"Curr_ownership\"], axis=1, inplace=True)\n",
    "    #ערכים לא הגיוניים לאחר שבדקנו בגרפים\n",
    "    dataset=dataset[dataset['capacity_Engine']<8000]\n",
    "    dataset=dataset[dataset['capacity_Engine']>150]\n",
    "    dataset=dataset[dataset['Km']<500000]\n",
    "    \n",
    "    \n",
    "    # חישוב יחס קילומטראז' לגיל הרכב\n",
    "    dataset['Km_per_Year'] = dataset['Km'] / dataset['Car_Age']\n",
    "\n",
    "    # חישוב כמה זמן עבר מאז תאריך יצירת המודעה\n",
    "    dataset['Days_Since_Creation'] = (datetime.now() - dataset['Cre_date']).dt.days\n",
    "\n",
    "    # יצירת משתנה בינארי האם פורסם מחדש או לא\n",
    "    dataset['Republished'] = (dataset['Cre_date'] != dataset['Repub_date']).astype(int)\n",
    "    \n",
    "    # מצא ומחק כפילויות\n",
    "    dataset = dataset.drop_duplicates()\n",
    "    dataset.drop(['Cre_date', 'Repub_date','Year',\"Description\"], axis=1, inplace=True)\n",
    "    \n",
    "    #דירוג לפי יוקרתיות\n",
    "    car_brands = {\n",
    "    \"מרצדס\": 1,\n",
    "    \"ב.מ.וו\": 2,\n",
    "    \"אאודי\": 3,\n",
    "    \"לקסוס\": 4,\n",
    "    \"וולוו\": 5,\n",
    "    \"פולקסווגן\": 6,\n",
    "    \"מיני\": 7,\n",
    "    \"טויוטה\": 8,\n",
    "    \"הונדה\": 9,\n",
    "    \"מאזדה\": 10,\n",
    "    \"סובארו\": 11,\n",
    "    \"פורד\": 12,\n",
    "    \"ניסאן\": 13,\n",
    "    \"שברולט\": 14,\n",
    "    \"קרייזלר\": 15,\n",
    "    \"יונדאי\": 16,\n",
    "    \"קיה\": 17,\n",
    "    \"סקודה\": 18,\n",
    "    \"אופל\": 19,\n",
    "    \"פיג'ו\": 20,\n",
    "    \"סיטרואן\": 21,\n",
    "    \"רנו\": 22,\n",
    "    \"מיצובישי\": 23,\n",
    "    \"סוזוקי\": 24,\n",
    "    \"דייהטסו\": 25\n",
    "    }\n",
    "    dataset['company_rank'] = dataset['manufactor'].map(car_brands)\n",
    "    dataset.drop(['manufactor'], axis=1, inplace=True)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfcba1b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=prepare_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efae0a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Root Mean Squared Error (RMSE) on test set: 9576.765330871649\n",
      "Mean RMSE: 12649.874384534429\n",
      "Standard Deviation of RMSE: 2017.8821818779954\n",
      "Mean R2: 0.6695366735503417\n",
      "Standard Deviation of R2: 0.12024822384320508\n",
      "Top 5 most influential features:\n",
      "Car_Age            120832.910143\n",
      "model_לאונה         72899.053207\n",
      "model_קורבט         69452.258227\n",
      "Km                  50199.393906\n",
      "capacity_Engine     44699.199044\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "columns_to_normalize = ['Car_Age', 'Hand', 'capacity_Engine', 'Km', 'Km_per_Year', 'company_rank', 'Days_Since_Creation']\n",
    "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "\n",
    "#   משתנים ללא עיר,צבע,מספר תמונות ומחוז שזה עם המון פיצ'רים שלא רלוונטים\n",
    "X = df[['model', 'Hand', 'Gear', 'capacity_Engine', 'Engine_type',\n",
    "         'Km', 'Car_Age', 'Region',\n",
    "       'Km_per_Year', 'Days_Since_Creation', 'Republished', 'company_rank']] # משתני ההסברה\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = df['Price']  # משתנה המטרה\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Hyperparameter tuning using Grid Search \n",
    "param_grid = {\n",
    "    'alpha': [0.01,0.05, 0.1, 1, 10],\n",
    "    'l1_ratio': [ 0.3, 0.5, 0.7,0.85, 0.9, 0.95, 1]\n",
    "}\n",
    "\n",
    "elastic_net = ElasticNet(random_state=42)\n",
    "grid_search = GridSearchCV(elastic_net, param_grid, cv=10, scoring='neg_mean_squared_error',verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from Grid Search\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "# הערכת ביצועי המודל\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# יצירת DataFrame של הנתונים המקוריים עם העמודות y_pred ו-y_test\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)  # הפיכת X_test ל-DataFrame עם שמות העמודות המקוריים\n",
    "X_test_df['y_test'] = y_test.values  # הוספת עמודת y_test\n",
    "X_test_df['y_pred'] = y_pred  # הוספת עמודת y_pred\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'Root Mean Squared Error (RMSE) on test set: {rmse}')\n",
    "\n",
    "# חיזוי על ידי 10-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 10-fold cross-validation with multiple metrics\n",
    "scoring = ['neg_root_mean_squared_error', 'r2']\n",
    "cv_results = cross_validate(model, X_train, y_train, cv=10, scoring=scoring, return_train_score=False)\n",
    "\n",
    "# Calculate the mean and standard deviation of RMSE and R2 scores\n",
    "mean_rmse = -np.mean(cv_results['test_neg_root_mean_squared_error'])\n",
    "std_rmse = np.std(cv_results['test_neg_root_mean_squared_error'])\n",
    "mean_r2 = np.mean(cv_results['test_r2'])\n",
    "std_r2 = np.std(cv_results['test_r2'])\n",
    "\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Standard Deviation of RMSE: {std_rmse}\")\n",
    "print(f\"Mean R2: {mean_r2}\")\n",
    "print(f\"Standard Deviation of R2: {std_r2}\")\n",
    "\n",
    "# חפש את המאפיינים עם השפעה הגדולה ביותר על החיזוי\n",
    "feature_importances = pd.Series(model.coef_, index=X_train.columns)\n",
    "top_features = feature_importances.abs().nlargest(5)\n",
    "print(f'Top 5 most influential features:\\n{top_features}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d8381",
   "metadata": {},
   "source": [
    "Root Mean Squared Error (RMSE) בקבוצת הבדיקה מתגבש על 9576.77, מה שמעיד על הממוצע הממוצע של השגיאה בין הערכים הצפויים לבין הערכים האמיתיים בקבוצת הבדיקה.\n",
    "\n",
    "Mean RMSE מצביע על הערך הממוצע של RMSE במספר הקיפולים או הבדיקות השונות, כאשר הערך שלך הוא 12649.87. זה מעיד על ביצועים יציבים של המודל על מספר הנתונים השונים.\n",
    "\n",
    "Standard Deviation of RMSE מספק פיזור של השגיאה בין הקיפולים או הבדיקות, המתפרס בטווח של 2017.88. ערכים נמוכים יותר מציינים קיבולת יעילה יותר של המודל בניתוח וניסוי של הנתונים.\n",
    "\n",
    "Mean R2 מתצבע ב-0.67, מה שהוא סימן להיתקף טוב של המודל באופן כללי. המדד עוזר לקבוע כמה מההירות התחרות הכלליים בנתונים יכולה להיות ניספו"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721ac33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
